{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e5d62c",
   "metadata": {
    "id": "a3e5d62c"
   },
   "source": [
    "# <center> **Audio Classification using Deep Learning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HOBk4GO5gAZb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOBk4GO5gAZb",
    "outputId": "4ae2ca9d-8ede-4ac4-8014-b87a8f2a2b46"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e4d12a",
   "metadata": {
    "id": "f7e4d12a"
   },
   "source": [
    "# **Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-element",
   "metadata": {
    "id": "protective-element",
    "papermill": {
     "duration": 0.013982,
     "end_time": "2021-05-18T13:45:42.795693",
     "exception": false,
     "start_time": "2021-05-18T13:45:42.781711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing and installing the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c17f11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6c17f11",
    "outputId": "302bdcb9-e713-483b-828b-de50ebb5e4df"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"{package} est déjà installé.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} n'est pas installé. Installation en cours...\")\n",
    "        !pip install {package}\n",
    "    finally:\n",
    "        globals()[package] = importlib.import_module(package)\n",
    "        print(f\"{package} est maintenant importé.\")\n",
    "\n",
    "# Vérifier et installer les bibliothèques nécessaires\n",
    "libraries_to_check = ['IPython', 'librosa', 'shutil', 'pandas', 'os', 'time', 'warnings', 'random',\n",
    "                      'seaborn', 'numpy', 'tqdm', 'matplotlib', 'sklearn', 'tensorflow' , 'resampy' ]\n",
    "\n",
    "all_libraries_found = True\n",
    "\n",
    "for library in libraries_to_check:\n",
    "    try:\n",
    "        importlib.import_module(library)\n",
    "        print(f\"{library} est déjà installé.\")\n",
    "    except ImportError:\n",
    "        print(f\"{library} n'est pas installé. Installation en cours...\")\n",
    "        !pip install {library}\n",
    "        all_libraries_found = False\n",
    "\n",
    "# Afficher un message de confirmation\n",
    "if all_libraries_found:\n",
    "    print(\"Toutes les bibliothèques nécessaires sont installées et importées.\")\n",
    "else:\n",
    "    print(\"Certaines bibliothèques ont été installées et importées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-edmonton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T13:45:42.835137Z",
     "iopub.status.busy": "2021-05-18T13:45:42.834459Z",
     "iopub.status.idle": "2021-05-18T13:45:49.403706Z",
     "shell.execute_reply": "2021-05-18T13:45:49.402732Z"
    },
    "id": "fancy-edmonton",
    "papermill": {
     "duration": 6.594003,
     "end_time": "2021-05-18T13:45:49.403865",
     "exception": false,
     "start_time": "2021-05-18T13:45:42.809862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import joblib\n",
    "import librosa.display\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os, time, warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-resort",
   "metadata": {
    "id": "elegant-resort",
    "papermill": {
     "duration": 0.014401,
     "end_time": "2021-05-18T13:45:49.434477",
     "exception": false,
     "start_time": "2021-05-18T13:45:49.420076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating DataFrame For models Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a8818",
   "metadata": {
    "id": "1f9a8818"
   },
   "outputs": [],
   "source": [
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb3feb",
   "metadata": {
    "id": "80fb3feb"
   },
   "source": [
    "# **Data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383c0b9",
   "metadata": {
    "id": "1383c0b9"
   },
   "source": [
    "## Convert Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e570",
   "metadata": {
    "id": "2ba6e570"
   },
   "outputs": [],
   "source": [
    "def convert_ogg_to_wav(input_file, output_file):\n",
    "    data, samplerate = soundfile.read(input_file)\n",
    "    soundfile.write(output_file, data, samplerate, format='WAV', subtype='PCM_16')\n",
    "\n",
    "def convert_folder_ogg_to_wav(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ogg\"):\n",
    "                ogg_path = os.path.join(root, file)\n",
    "                wav_path = os.path.splitext(ogg_path)[0] + \".wav\"\n",
    "                convert_ogg_to_wav(ogg_path, wav_path)\n",
    "                print(f\"Conversion: {ogg_path} -> {wav_path}\")\n",
    "                os.remove(ogg_path)\n",
    "\n",
    "\n",
    "data_folder = 'data'\n",
    "\n",
    "convert_folder_ogg_to_wav(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "br50yJMsiBq3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "br50yJMsiBq3",
    "outputId": "392e8d01-1ca0-4dd2-fadc-7e96833de16c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Spécifiez le chemin du dossier à nettoyer\n",
    "dossier_a_nettoyer = 'data/all_data'\n",
    "\n",
    "# Vérifiez si le dossier existe\n",
    "if os.path.exists(dossier_a_nettoyer):\n",
    "    # Parcourez tous les fichiers du dossier\n",
    "    for fichier in os.listdir(dossier_a_nettoyer):\n",
    "        chemin_fichier = os.path.join(dossier_a_nettoyer, fichier)\n",
    "        try:\n",
    "            if os.path.isfile(chemin_fichier):\n",
    "                # Supprimez le fichier\n",
    "                os.unlink(chemin_fichier)\n",
    "            elif os.path.isdir(chemin_fichier):\n",
    "                # Supprimez le dossier récursivement\n",
    "                shutil.rmtree(chemin_fichier)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la suppression du fichier {chemin_fichier}: {e}\")\n",
    "\n",
    "    print(f\"Tous les fichiers dans {dossier_a_nettoyer} ont été supprimés.\")\n",
    "else:\n",
    "    print(f\"Le dossier {dossier_a_nettoyer} n'existe pas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97d7df",
   "metadata": {
    "id": "ed97d7df"
   },
   "source": [
    "## Create Audio Folder and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081aead",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e081aead",
    "outputId": "e12da5ae-0dd5-4b7c-eef9-87604c9e5885"
   },
   "outputs": [],
   "source": [
    "def create_all_data_folder(root_folder, output_folder=\"all_data\", csv_filename=\"data.csv\"):\n",
    "    # Créer le chemin du dossier all_data\n",
    "    all_data_path = os.path.join(root_folder, output_folder)\n",
    "\n",
    "    # Vérifier si le dossier all_data existe, sinon le créer\n",
    "    if not os.path.exists(all_data_path):\n",
    "        os.makedirs(all_data_path)\n",
    "        print(f\"Le dossier {output_folder} a été créé avec succès.\")\n",
    "\n",
    "    # Obtenir la liste des fichiers dans le dossier all_data\n",
    "    existing_files = os.listdir(all_data_path)\n",
    "\n",
    "    # Vérifier si le dossier all_data est déjà rempli\n",
    "    if existing_files:\n",
    "        print(f\"Le dossier {output_folder} n'est pas vide. Aucune action nécessaire.\")\n",
    "        return\n",
    "\n",
    "    # Parcourir les sous-dossiers (classes) dans le dossier racine\n",
    "    classes = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d)) and d != output_folder]\n",
    "\n",
    "\n",
    "    # Liste pour stocker les informations sur les fichiers audio\n",
    "    metadata = []\n",
    "\n",
    "    for audio_class in classes:\n",
    "        class_path = os.path.join(root_folder, audio_class)\n",
    "\n",
    "        if os.path.isdir(class_path):\n",
    "            # Parcourir les fichiers audio dans chaque classe\n",
    "            audio_files = [f for f in os.listdir(class_path) if f.endswith(\".wav\")]\n",
    "\n",
    "            # Mélanger les fichiers audio\n",
    "            random.shuffle(audio_files)\n",
    "\n",
    "            # Copier les fichiers dans le dossier all_data\n",
    "            for audio_file in audio_files:\n",
    "                source_path = os.path.join(class_path, audio_file)\n",
    "                dest_path = os.path.join(all_data_path, audio_file)\n",
    "                shutil.copyfile(source_path, dest_path)  # Utiliser shutil.copyfile pour copier les fichiers\n",
    "\n",
    "                # Ajouter les informations à la liste metadata\n",
    "                metadata.append({\"file\": audio_file, \"class\": audio_class})\n",
    "\n",
    "    # Créer un DataFrame avec les métadonnées\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Sauvegarder les métadonnées dans un fichier CSV\n",
    "    csv_path = os.path.join(all_data_path, csv_filename)\n",
    "    metadata_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"Le fichier CSV {csv_filename} a été créé dans le dossier {output_folder}.\")\n",
    "\n",
    "\n",
    "root_folder = \"data\"\n",
    "create_all_data_folder(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502fca4",
   "metadata": {
    "id": "d502fca4"
   },
   "source": [
    "## Reading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-momentum",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T13:45:49.470452Z",
     "iopub.status.busy": "2021-05-18T13:45:49.469965Z",
     "iopub.status.idle": "2021-05-18T13:45:49.513057Z",
     "shell.execute_reply": "2021-05-18T13:45:49.513481Z"
    },
    "id": "round-momentum",
    "outputId": "7de7fe12-c544-4016-a8a6-2cf008444efd",
    "papermill": {
     "duration": 0.064841,
     "end_time": "2021-05-18T13:45:49.513660",
     "exception": false,
     "start_time": "2021-05-18T13:45:49.448819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the files\n",
    "audio_dataset_path = \"data/all_data/\"\n",
    "\n",
    "# loading the csv\n",
    "meta_data = pd.read_csv(\"data/all_data/data.csv\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Baby\", value=\"Baby\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Chainsaw\", value=\"Chainsaw\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Clocktick\", value=\"Clock Tick\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Cow\", value=\"Cow\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Dog\", value=\"Dog\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Fire\", value=\"Fire\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Frog\", value=\"Frog\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Helicopter\", value=\"Helicopter\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Pig\", value=\"Pig\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Rain\", value=\"Rain\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Rooster\", value=\"Rooster\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Sea\", value=\"Sea\")\n",
    "meta_data[\"class\"] = meta_data[\"class\"].replace(to_replace=\"Sneeze\", value=\"Sneeze\")\n",
    "\n",
    "meta_data[\"classID\"] = pd.factorize(meta_data[\"class\"])[0]\n",
    "\n",
    "\n",
    "print(meta_data.head())\n",
    "\n",
    "meta_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f9fa7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f02f9fa7",
    "outputId": "1236410a-fbbd-4126-b40d-c375d1e8cb28"
   },
   "outputs": [],
   "source": [
    "meta_data.groupby(\"classID\")[\"class\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb434592",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "eb434592",
    "outputId": "d7b30aa5-f97a-4e37-f343-9643a76acb49"
   },
   "outputs": [],
   "source": [
    "x = meta_data[\"class\"].unique()\n",
    "y = meta_data[\"class\"].value_counts(ascending=True)\n",
    "ind = np.arange(len(y))\n",
    "# plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.barh(ind, y)\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.gcf().set_dpi(500)\n",
    "plt.title(\"Number of Audio Samples per Category\")\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba499520",
   "metadata": {
    "id": "ba499520"
   },
   "source": [
    "# **MFCC Visualization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e69ca1",
   "metadata": {
    "id": "59e69ca1"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"figure.dpi\"] = 80\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7577b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "49d7577b",
    "outputId": "817fee52-bfe9-43cc-cb82-ae26b60630c0"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"1-187207-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Baby Crying\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3aff8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "b2b3aff8",
    "outputId": "0068867b-0a12-4f89-a392-fd35fc3be688"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"2-50667-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Chainsaw\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e2a8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "597e2a8f",
    "outputId": "2ec7a9b8-bee0-49c1-e63d-4b7eca5422fd"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"4-198965-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of ClockTick\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0a4f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "f9b0a4f0",
    "outputId": "6feda7c0-55e8-4f84-e3c6-3b4426c9cc4f"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"1-77241-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Cow\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b549b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "f91b549b",
    "outputId": "3b1a4772-f524-4e02-d934-e8be62b3be8d"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"3-144028-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Dog Barking\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05287049",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "05287049",
    "outputId": "cbbcbeab-1b80-46dd-ad4e-903ee02dc8e6"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"4-182368-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Fire Crackling\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d563e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "4e9d563e",
    "outputId": "794396ae-8752-44d1-da0b-c04222fa7367"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"5-189795-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Frog sound\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8baf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "e0e8baf4",
    "outputId": "d62b41ac-7de1-42c5-9746-d886c33edde4"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"5-177957-C.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Helicopter sound\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76125059",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "76125059",
    "outputId": "6e4a0d62-8b7b-4351-a64c-25f0dfc26c11"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"3-257858-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Pig\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64420ff7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "64420ff7",
    "outputId": "6797c96e-48a8-46e5-9494-f6b66b90e869"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"2-117625-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Rain\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d813c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "452d813c",
    "outputId": "f3b13907-a26c-4177-cddb-e4de4f58d29e"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"3-137152-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Rooster\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe61b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "a8fe61b8",
    "outputId": "2cfcac66-35b9-40fd-dc97-f9f90a444a64"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"5-219379-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Sea Waves\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca1626",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "25ca1626",
    "outputId": "c1fa5931-08b8-4db4-f382-4d9c27214758"
   },
   "outputs": [],
   "source": [
    "audio_path = audio_dataset_path + \"2-93030-A.wav\"\n",
    "(xf, sr) = librosa.load(audio_path)\n",
    "mfccs = librosa.feature.mfcc(y=xf, sr=sr, n_mfcc=40)\n",
    "librosa.display.specshow(mfccs, x_axis=\"time\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.title(\"MFCC Of Person Sneeze\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91111924",
   "metadata": {
    "id": "91111924"
   },
   "source": [
    "# **Feature Extraction and Database Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570532f",
   "metadata": {
    "id": "d570532f"
   },
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb482c",
   "metadata": {
    "id": "a8bb482c"
   },
   "source": [
    "1. We have used Librosa to preprocess audio file.\n",
    "2. To do so, I will go through each fold and extract the data from each file using librosa's mfcc function.\n",
    "3. The extracted data is appended in a list and stored in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8784b67",
   "metadata": {
    "id": "e8784b67"
   },
   "source": [
    "### The function bellow will extract mfcc feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62202b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a62202b5",
    "outputId": "5ac41211-b595-4160-ef57-a8c19f4dc21d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted = []\n",
    "\n",
    "for index_num, row in tqdm(meta_data.iterrows()):\n",
    "    # Recuperer le fichier\n",
    "    file_name = os.path.join(\n",
    "        os.path.abspath(audio_dataset_path),\n",
    "        row[\"file\"]\n",
    "    )\n",
    "    # Recuperer La Classe\n",
    "    final_class_labels = row[\"class\"]\n",
    "    # Importer les fichiers audio\n",
    "    audio, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # Extraction des caracterestiques\n",
    "    feature = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "    # Normalisation des caracterestiques\n",
    "    scaled_feature = np.mean(feature.T, axis=0)\n",
    "    # Stocker dans une liste\n",
    "    extracted.append([scaled_feature, final_class_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-coast",
   "metadata": {
    "id": "informative-coast",
    "papermill": {
     "duration": 1.548527,
     "end_time": "2021-05-18T14:01:07.480813",
     "exception": false,
     "start_time": "2021-05-18T14:01:05.932286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using a dataframe and pickle to save the extracted features array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0edb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44b0edb0",
    "outputId": "7e2fcb0d-c209-4fe0-e0f5-d658cf3273f1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convertir la liste extracted en DataFrame\n",
    "columns = [\"features\", \"class\"]\n",
    "extracted_df = pd.DataFrame(extracted, columns=columns)\n",
    "\n",
    "# Enregistrer le DataFrame dans un fichier CSV\n",
    "output_csv_path = \"data/feature.csv\"\n",
    "extracted_df.to_csv(output_csv_path, index=False)\n",
    "extracted_df.to_pickle(\"extracted_df.pkl\")\n",
    "extracted_df.head()\n",
    "print(f\"Les caractéristiques ont été enregistrées dans {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd97538",
   "metadata": {
    "id": "fbd97538"
   },
   "source": [
    "# **Data Preprocessing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-oxide",
   "metadata": {
    "id": "greenhouse-oxide",
    "papermill": {
     "duration": 1.556269,
     "end_time": "2021-05-18T14:01:14.010539",
     "exception": false,
     "start_time": "2021-05-18T14:01:12.454270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Distribute the data to X and Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a4d59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a4a4d59",
    "outputId": "f8b6a08c-3aac-480f-89d3-990cb00a880c"
   },
   "outputs": [],
   "source": [
    "final = pd.read_pickle(\"extracted_df.pkl\")\n",
    "X = np.array(final[\"features\"].tolist())\n",
    "y = np.array(final[\"class\"].tolist())\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-genius",
   "metadata": {
    "id": "breathing-genius",
    "papermill": {
     "duration": 1.6095,
     "end_time": "2021-05-18T14:01:20.316376",
     "exception": false,
     "start_time": "2021-05-18T14:01:18.706876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using LabelEncoder() to encode the string labels to an integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-state",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:23.681388Z",
     "iopub.status.busy": "2021-05-18T14:01:23.680865Z",
     "iopub.status.idle": "2021-05-18T14:01:23.684868Z",
     "shell.execute_reply": "2021-05-18T14:01:23.684397Z"
    },
    "id": "domestic-state",
    "outputId": "fd5a75cf-74bf-4e4d-c318-65f6e73abcd1",
    "papermill": {
     "duration": 1.583578,
     "end_time": "2021-05-18T14:01:23.684982",
     "exception": false,
     "start_time": "2021-05-18T14:01:22.101404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# codage des classes\n",
    "le = LabelEncoder()\n",
    "\n",
    "# transform each category with it's respected label\n",
    "Y = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# Sauvegardez l'objet LabelEncoder\n",
    "joblib.dump(le, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-discharge",
   "metadata": {
    "id": "young-discharge",
    "papermill": {
     "duration": 1.572854,
     "end_time": "2021-05-18T14:01:26.836045",
     "exception": false,
     "start_time": "2021-05-18T14:01:25.263191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split the data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-graphics",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:30.528635Z",
     "iopub.status.busy": "2021-05-18T14:01:30.527743Z",
     "iopub.status.idle": "2021-05-18T14:01:30.535830Z",
     "shell.execute_reply": "2021-05-18T14:01:30.535190Z"
    },
    "id": "ceramic-graphics",
    "outputId": "dedfaf8c-abd5-45f5-ac9e-2179c7750034",
    "papermill": {
     "duration": 1.646809,
     "end_time": "2021-05-18T14:01:30.536014",
     "exception": false,
     "start_time": "2021-05-18T14:01:28.889205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# diviser les données de test et d'apprentissage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Number of training samples = \", X_train.shape[0])\n",
    "print(\"Number of testing samples = \", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e753d4",
   "metadata": {
    "id": "f7e753d4"
   },
   "source": [
    "# **Model 1 - ANN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-render",
   "metadata": {
    "id": "textile-render",
    "papermill": {
     "duration": 1.581455,
     "end_time": "2021-05-18T14:01:33.935793",
     "exception": false,
     "start_time": "2021-05-18T14:01:32.354338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-machine",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:37.118145Z",
     "iopub.status.busy": "2021-05-18T14:01:37.117610Z",
     "iopub.status.idle": "2021-05-18T14:01:39.261039Z",
     "shell.execute_reply": "2021-05-18T14:01:39.260076Z"
    },
    "id": "agreed-machine",
    "outputId": "21786775-960c-4801-e244-1a403d0737a8",
    "papermill": {
     "duration": 3.742495,
     "end_time": "2021-05-18T14:01:39.261194",
     "exception": false,
     "start_time": "2021-05-18T14:01:35.518699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construction du model\n",
    "\n",
    "num_labels = Y.shape[1]\n",
    "ANN_Model = Sequential()\n",
    "ANN_Model.add(Dense(1000, activation=\"relu\", input_shape=(128,)))\n",
    "ANN_Model.add(Dense(750, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(500, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(250, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(100, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(50, activation=\"relu\"))\n",
    "ANN_Model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "ANN_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-transportation",
   "metadata": {
    "id": "explicit-transportation",
    "papermill": {
     "duration": 1.71757,
     "end_time": "2021-05-18T14:01:42.553695",
     "exception": false,
     "start_time": "2021-05-18T14:01:40.836125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compiling the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-benchmark",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:45.785340Z",
     "iopub.status.busy": "2021-05-18T14:01:45.784541Z",
     "iopub.status.idle": "2021-05-18T14:01:45.791383Z",
     "shell.execute_reply": "2021-05-18T14:01:45.791916Z"
    },
    "id": "sharp-benchmark",
    "papermill": {
     "duration": 1.570325,
     "end_time": "2021-05-18T14:01:45.792052",
     "exception": false,
     "start_time": "2021-05-18T14:01:44.221727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ANN_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-machinery",
   "metadata": {
    "id": "objective-machinery",
    "papermill": {
     "duration": 1.560171,
     "end_time": "2021-05-18T14:01:48.907097",
     "exception": false,
     "start_time": "2021-05-18T14:01:47.346926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-metabolism",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T14:01:52.113048Z",
     "iopub.status.busy": "2021-05-18T14:01:52.112508Z",
     "iopub.status.idle": "2021-05-18T14:03:33.704926Z",
     "shell.execute_reply": "2021-05-18T14:03:33.663057Z"
    },
    "id": "extensive-metabolism",
    "outputId": "944eb421-ca0e-47d4-dbe4-3e3ef31ca857",
    "papermill": {
     "duration": 103.168786,
     "end_time": "2021-05-18T14:03:33.705066",
     "exception": false,
     "start_time": "2021-05-18T14:01:50.536280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 250\n",
    "num_batch_size = 64\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "ANN_Results = ANN_Model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=num_batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "\n",
    "ANN_Model.save(\"Audio_Classifier_ANN.h5\")\n",
    "print(\"ANN Model Saved\")\n",
    "train_hist_m1 = pd.DataFrame(ANN_Results.history)\n",
    "train_m1 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b404021",
   "metadata": {
    "id": "0b404021"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87b0fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "5d87b0fe",
    "outputId": "41233a4e-327c-439e-971b-9e2371ca04ef"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m1[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a27e1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "24a27e1f",
    "outputId": "d0b42d4c-ffd0-4dd7-a8c3-19e6b6c7b3ba"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m1[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0fbe8",
   "metadata": {
    "id": "b8e0fbe8"
   },
   "outputs": [],
   "source": [
    "# Mesurer les performances et ajouter une entrée au DataFrame log\n",
    "acc_m1 = ANN_Model.evaluate(X_test, y_test, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m1 = ANN_Model.predict(X_test, verbose=0)\n",
    "pred_m1 = round(time.time() - t0, 3)\n",
    "\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"ANN\"\n",
    "accuracy = acc_m1[1] * 100\n",
    "training_time = train_m1\n",
    "prediction_time = pred_m1\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-julian",
   "metadata": {
    "id": "vital-julian",
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ANN Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab55be",
   "metadata": {
    "id": "22ab55be"
   },
   "outputs": [],
   "source": [
    "# fonction de prediction avec le modele ANN\n",
    "def ANN_Prediction(file_name):\n",
    "    # load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # get the feature\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "    # scale the features\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "    # array of features\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "    # get the id of label using argmax\n",
    "    predicted_vector = np.argmax(ANN_Model.predict(prediction_feature), axis=-1)\n",
    "    # get the class label from class id\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    # display the result\n",
    "    print(\"ANN has predicted the class as  --> \", predicted_class[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-charles",
   "metadata": {
    "id": "minimal-charles",
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e0ba6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "309e0ba6",
    "outputId": "b63c516b-eae4-4d50-8f51-87fcaff1a2a2"
   },
   "outputs": [],
   "source": [
    "# Repertoire et nom du fichier\n",
    "file_name = audio_dataset_path + \"2-93030-A.wav\"\n",
    "# Fonction de prediction\n",
    "ANN_Prediction(file_name)\n",
    "# Jouer l'audio\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745bc49",
   "metadata": {
    "id": "0745bc49"
   },
   "source": [
    "# **Model 2 - CNN1D**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ecf18",
   "metadata": {
    "id": "e26ecf18"
   },
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea002582",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea002582",
    "outputId": "eb5dfe67-58a4-4d32-dddc-7d4b95519463"
   },
   "outputs": [],
   "source": [
    "xTrainval, xTest, yTrainval, yTest = train_test_split(\n",
    "    X, Y, test_size=0.1, stratify=y, random_state=387\n",
    ")\n",
    "xTrain, xvalid, yTrain, yvalid = train_test_split(\n",
    "    xTrainval, yTrainval, test_size=0.2, stratify=yTrainval, random_state=387\n",
    ")\n",
    "print(\"\\nNumber of samples for Train set :\", xTrain.shape[0])\n",
    "print(\"Number of samples for Validation set :\", xvalid.shape[0])\n",
    "print(\"Number of samples for Test set :\", xTest.shape[0])\n",
    "\n",
    "xTrain = np.expand_dims(xTrain, axis=2)\n",
    "xvalid = np.expand_dims(xvalid, axis=2)\n",
    "\n",
    "print(\"Shape of X Train\", xTrain.shape)\n",
    "print(\"Shape of X Test\", xTest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ec0b7",
   "metadata": {
    "id": "1e5ec0b7"
   },
   "source": [
    "## Building the CNN1D Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026718c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6026718c",
    "outputId": "73122237-2650-4c13-87f5-5818908dfaac"
   },
   "outputs": [],
   "source": [
    "CNN1D_Model = Sequential()\n",
    "CNN1D_Model.add(\n",
    "    Conv1D(\n",
    "        256,\n",
    "        5,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        input_shape=(xTrain.shape[1], 1),\n",
    "    )\n",
    ")\n",
    "CNN1D_Model.add(BatchNormalization())\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(256, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(128, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Conv1D(64, 5, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(MaxPooling1D(3, strides=2, padding=\"same\"))\n",
    "CNN1D_Model.add(Flatten())\n",
    "CNN1D_Model.add(Dense(units=1024, activation=\"relu\"))\n",
    "CNN1D_Model.add(Dropout(0.3))\n",
    "CNN1D_Model.add(Dense(units=13, activation=\"softmax\"))\n",
    "CNN1D_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec5b1",
   "metadata": {
    "id": "8a5ec5b1"
   },
   "source": [
    "## Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff66d2a",
   "metadata": {
    "id": "4ff66d2a"
   },
   "outputs": [],
   "source": [
    "CNN1D_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c6d28",
   "metadata": {
    "id": "506c6d28"
   },
   "source": [
    "## Fitting the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6099ae4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6099ae4",
    "outputId": "2cf08288-c98c-4dc1-9daf-3dd9383d8ad8"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "CNN1D_Results = CNN1D_Model.fit(\n",
    "    xTrain, yTrain, batch_size=64, epochs=250, validation_data=(xvalid, yvalid)\n",
    ")\n",
    "\n",
    "CNN1D_Model.save(\"Audio_Classifier_CNN1D.h5\")\n",
    "print(\"CNN1D Model Saved\")\n",
    "train_hist_m2 = pd.DataFrame(CNN1D_Results.history)\n",
    "train_m2 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e51a14",
   "metadata": {
    "id": "b7e51a14"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e4bc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "447e4bc0",
    "outputId": "f0731473-2ba1-4711-e91f-8c7581abc02a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m2[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb4e43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "e3bb4e43",
    "outputId": "67e07104-25e7-4150-db0f-d30e0db3ad2a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m2[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d9ce9",
   "metadata": {
    "id": "dd5d9ce9"
   },
   "outputs": [],
   "source": [
    "acc_m2 = CNN1D_Model.evaluate(xvalid, yvalid, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m2 = CNN1D_Model.predict(xvalid, verbose=0)\n",
    "pred_m2 = round(time.time() - t0, 3)\n",
    "\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"CNN_1D\"\n",
    "accuracy = acc_m2[1] * 100\n",
    "training_time = train_m2\n",
    "prediction_time = pred_m2\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860863ed",
   "metadata": {
    "id": "860863ed",
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN1D Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27afb5",
   "metadata": {
    "id": "bf27afb5"
   },
   "outputs": [],
   "source": [
    "# fonction de prediction CNN1D\n",
    "def CNN1D_Prediction(file_name):\n",
    "    # load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "    # get the feature\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "    # scale the features\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "    # array of features\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "    # expand dims\n",
    "    final_prediction_feature = np.expand_dims(prediction_feature, axis=2)\n",
    "    # get the id of label using argmax\n",
    "    predicted_vector = np.argmax(CNN1D_Model.predict(final_prediction_feature), axis=-1)\n",
    "    # get the class label from class id\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    # display the result\n",
    "    print(\"CNN1D has predicted the class as  --> \", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef8d35",
   "metadata": {
    "id": "80ef8d35",
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-adams",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "execution": {
     "iopub.execute_input": "2021-05-18T14:04:03.459573Z",
     "iopub.status.busy": "2021-05-18T14:04:03.459043Z",
     "iopub.status.idle": "2021-05-18T14:04:03.674741Z",
     "shell.execute_reply": "2021-05-18T14:04:03.675143Z"
    },
    "id": "liked-adams",
    "outputId": "5519fd16-df70-4877-cf61-3dbe411ad650",
    "papermill": {
     "duration": 2.315011,
     "end_time": "2021-05-18T14:04:03.675281",
     "exception": false,
     "start_time": "2021-05-18T14:04:01.360270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nom fichier\n",
    "file_name = audio_dataset_path + \"2-93030-A.wav\"\n",
    "# Fonction de prediction\n",
    "CNN1D_Prediction(file_name)\n",
    "# Jouer le fichier audio\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4617b9c",
   "metadata": {
    "id": "d4617b9c"
   },
   "source": [
    "# **Model 3 - CNN2D**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b209cf",
   "metadata": {
    "id": "31b209cf"
   },
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82493c6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82493c6e",
    "outputId": "190ecb84-9783-4a2f-aa59-7762dee67bf7"
   },
   "outputs": [],
   "source": [
    "xtrain = xTrain.reshape(xTrain.shape[0], 16, 8, 1)\n",
    "xtest = xTest.reshape(xTest.shape[0], 16, 8, 1)\n",
    "\n",
    "print(\"The Shape of X Train\", xtrain.shape)\n",
    "print(\"The Shape of Y Train\", yTrain.shape)\n",
    "print(\"The Shape of X Test\", xtest.shape)\n",
    "print(\"The Shape of Y Test\", yTest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef3cce",
   "metadata": {
    "id": "0bef3cce"
   },
   "source": [
    "## Building the CNN2D Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5086721",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5086721",
    "outputId": "b20aa9ff-ae91-478c-cfde-16addd77b594"
   },
   "outputs": [],
   "source": [
    "CNN2D_Model = Sequential()\n",
    "CNN2D_Model.add(\n",
    "    Conv2D(64, (3, 3), padding=\"same\", activation=\"tanh\", input_shape=(16, 8, 1))\n",
    ")\n",
    "CNN2D_Model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "CNN2D_Model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"tanh\"))\n",
    "CNN2D_Model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "CNN2D_Model.add(Dropout(0.1))\n",
    "CNN2D_Model.add(Flatten())\n",
    "CNN2D_Model.add(Dense(1024, activation=\"tanh\"))\n",
    "CNN2D_Model.add(Dense(13, activation=\"softmax\"))\n",
    "CNN2D_Model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a81586",
   "metadata": {
    "id": "20a81586"
   },
   "source": [
    "## Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd4e95",
   "metadata": {
    "id": "9bdd4e95"
   },
   "outputs": [],
   "source": [
    "CNN2D_Model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6de7af",
   "metadata": {
    "id": "7b6de7af"
   },
   "source": [
    "## Fitting the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464f12d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9464f12d",
    "outputId": "01236c8b-3b05-4a9a-fcc7-27326d99b547"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "CNN2D_Results = CNN2D_Model.fit(\n",
    "    xtrain, yTrain, epochs=250, batch_size=64, validation_data=(xtest, yTest)\n",
    ")\n",
    "\n",
    "CNN2D_Model.save(\"Audio_Classifier_CNN2D.h5\")\n",
    "print(\"CNN2D Model Saved\")\n",
    "train_hist_m3 = pd.DataFrame(CNN2D_Results.history)\n",
    "train_m3 = round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bcf1a2",
   "metadata": {
    "id": "a1bcf1a2"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e996553",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "9e996553",
    "outputId": "e7c01c3a-9985-4bfa-d947-ba13e09255a6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m3[[\"loss\", \"val_loss\"]])\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Loss Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4df53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "21e4df53",
    "outputId": "17d04da3-2633-4341-ac99-954c40fe2123"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "plt.plot(train_hist_m3[[\"accuracy\", \"val_accuracy\"]])\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Accuracy Per Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31334829",
   "metadata": {
    "id": "31334829"
   },
   "outputs": [],
   "source": [
    "acc_m3 = CNN2D_Model.evaluate(xtest, yTest, verbose=0)\n",
    "t0 = time.time()\n",
    "y_pred_m3 = CNN2D_Model.predict(xtest, verbose=0)\n",
    "pred_m3 = round(time.time() - t0, 3)\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"CNN_2D\"\n",
    "accuracy = acc_m3[1] * 100\n",
    "training_time = train_m3\n",
    "prediction_time = pred_m3\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864e81f",
   "metadata": {
    "id": "c864e81f",
    "papermill": {
     "duration": 2.034009,
     "end_time": "2021-05-18T14:03:41.813463",
     "exception": false,
     "start_time": "2021-05-18T14:03:39.779454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN2D Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee6f12",
   "metadata": {
    "id": "d0ee6f12"
   },
   "outputs": [],
   "source": [
    "# fonction de prediction CNN2D\n",
    "def CNN2D_Prediction(file_name):\n",
    "\n",
    "    audio_data, sample_rate = librosa.load(file_name, res_type=\"kaiser_fast\")\n",
    "\n",
    "    feature = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=128)\n",
    "\n",
    "    feature_scaled = np.mean(feature.T, axis=0)\n",
    "\n",
    "    prediction_feature = np.array([feature_scaled])\n",
    "\n",
    "    final_prediction_feature = prediction_feature.reshape(\n",
    "        prediction_feature.shape[0], 16, 8, 1\n",
    "    )\n",
    "\n",
    "    predicted_vector = np.argmax(CNN2D_Model.predict(final_prediction_feature), axis=-1)\n",
    "\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "\n",
    "    print(\"CNN2D has predicted the class as  --> \", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad739c",
   "metadata": {
    "id": "43ad739c",
    "papermill": {
     "duration": 2.014985,
     "end_time": "2021-05-18T14:03:59.338044",
     "exception": false,
     "start_time": "2021-05-18T14:03:57.323059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec185a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "50ec185a",
    "outputId": "ed5cf1f6-e1cb-4519-9529-ffc6edde00ef"
   },
   "outputs": [],
   "source": [
    "# Repertoire et nom du fichier audio\n",
    "file_name = audio_dataset_path + \"2-93030-A.wav\"\n",
    "# fonction de prediction\n",
    "CNN2D_Prediction(file_name)\n",
    "# jouer le fichier audio\n",
    "ipd.Audio(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff778937",
   "metadata": {
    "id": "ff778937"
   },
   "source": [
    "# <center> **Audio Classification using Machine Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc6ceb",
   "metadata": {
    "id": "dabc6ceb"
   },
   "source": [
    "## Pre Process Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529adb6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "529adb6a",
    "outputId": "bc27bff2-4706-4a90-829d-b6a16839d1f4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path, feature_types):\n",
    "    # import le fichier audio\n",
    "    audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "\n",
    "    # Extraction des caracterestiques selon les besoins\n",
    "    all_features = []\n",
    "\n",
    "    for feature_type in feature_types:\n",
    "        if feature_type == 'mfcc':\n",
    "            features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=128)\n",
    "        elif feature_type == 'chroma':\n",
    "            features = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "        elif feature_type == 'mel':\n",
    "            features = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        elif feature_type == 'contrast':\n",
    "            features = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "        elif feature_type == 'tonnetz':\n",
    "            features = librosa.feature.tonnetz(y=audio, sr=sr)\n",
    "\n",
    "\n",
    "        # Normalisation avec la moyenne\n",
    "        features_mean = features.mean(axis=1)\n",
    "        all_features.append(features_mean)\n",
    "\n",
    "    # Concatenate caracteristique si ya plusieurs\n",
    "    if len(all_features) > 1:\n",
    "        concatenated_features = np.concatenate(all_features)\n",
    "        return concatenated_features\n",
    "    else:\n",
    "        return all_features[0]\n",
    "\n",
    "# Charger les données à partir du fichier CSV\n",
    "csv_path = \"data/all_data/data.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Définir le chemin du répertoire des fichiers audio\n",
    "audio_dir = \"data/all_data\"\n",
    "\n",
    "# Créer une liste pour stocker les caractéristiques et les étiquettes\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Parcourir chaque ligne du DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    file_path = os.path.join(audio_dir, row['file'])\n",
    "\n",
    "    # Choisissez les types de caractéristiques que vous souhaitez extraire (par exemple, ['mfcc', 'mel', 'tonnetz'])\n",
    "    feature_types = ['mfcc']\n",
    "\n",
    "    # Extraction des caracterestique selon les besoins\n",
    "    extracted_features = extract_features(file_path, feature_types)\n",
    "\n",
    "    # Ajouter les caractéristiques et l'étiquette à la liste\n",
    "    features.append(extracted_features)\n",
    "    labels.append(row['class'])\n",
    "\n",
    "# Convertir les listes en DataFrame\n",
    "feature_columns = [f\"feature_{i}\" for i in range(len(features[0]))]\n",
    "features_df = pd.DataFrame(features, columns=feature_columns)\n",
    "labels_df = pd.DataFrame(labels, columns=['class'])\n",
    "\n",
    "# Concaténer les features et les labels\n",
    "result_df = pd.concat([features_df, labels_df], axis=1)\n",
    "\n",
    "# Sauvegarder le DataFrame dans un fichier CSV\n",
    "result_csv_path = \"data/feature_ML.csv\"\n",
    "result_df.to_csv(result_csv_path, index=False)\n",
    "\n",
    "print(f\"Extracted features saved to {result_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b377f",
   "metadata": {
    "id": "1b0b377f"
   },
   "source": [
    "## Distribute the data to X and Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba3ce5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0ba3ce5",
    "outputId": "c8539b3a-9856-4909-aeb9-3fb88e1b69ee"
   },
   "outputs": [],
   "source": [
    "# Convertir les listes en tableaux NumPy\n",
    "X = pd.DataFrame(features)\n",
    "y = pd.Series(labels)\n",
    "print(X)\n",
    "# Encoder les étiquettes (classes)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d447cf",
   "metadata": {
    "id": "26d447cf"
   },
   "source": [
    "## Prediction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0987fda",
   "metadata": {
    "id": "c0987fda"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ML_prediction(file_path, model_path, feature_types):\n",
    "    # Charger le modèle et l'encodeur de labels à partir des fichiers sauvegardés\n",
    "    model = joblib.load(model_path)\n",
    "    label_encoder = joblib.load('label_encoder.joblib')\n",
    "\n",
    "    # Extraire les caractéristiques du fichier audio\n",
    "    extracted_features = extract_features(file_path, feature_types)\n",
    "\n",
    "    # Convertir les caractéristiques en tableau NumPy\n",
    "    features_array = np.array([extracted_features])\n",
    "\n",
    "    # Assurer que le tableau est C-contiguous\n",
    "    features_array = np.ascontiguousarray(features_array)\n",
    "\n",
    "    # Effectuer la prédiction\n",
    "    prediction = model.predict(features_array)\n",
    "\n",
    "    # Convertir la prédiction en classe réelle\n",
    "    predicted_class = label_encoder.inverse_transform(prediction)[0]\n",
    "    print(\"Predicted class: \", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40c85c",
   "metadata": {
    "id": "8e40c85c"
   },
   "source": [
    "# **Model 4 - Gaussian NB**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49a43c",
   "metadata": {
    "id": "4a49a43c"
   },
   "source": [
    "## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445aff38",
   "metadata": {
    "id": "445aff38"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "\n",
    "# Créer le classificateur Naive Bayes gaussien\n",
    "model_GaussNB = GaussianNB()\n",
    "\n",
    "# Mesurer le temps d'entraînement\n",
    "start_time = time.time()\n",
    "model_GaussNB.fit(X_train, y_train)\n",
    "train_m4 = time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beb9a2",
   "metadata": {
    "id": "f5beb9a2"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060d693",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "1060d693",
    "outputId": "cc5aecf9-a900-4c6d-de80-77e5a3213343"
   },
   "outputs": [],
   "source": [
    "# Afficher la précision par classe\n",
    "y_pred = model_GaussNB.predict(X_test)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Extraire les précisions par classe\n",
    "precisions = [class_report[label]['precision'] for label in label_encoder.classes_]\n",
    "\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_encoder.classes_, y=precisions)\n",
    "plt.title('Précision par classe')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Précision')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb9822",
   "metadata": {
    "id": "7acb9822"
   },
   "outputs": [],
   "source": [
    "# Mesurer le temps de prédiction\n",
    "start_time = time.time()\n",
    "y_pred = model_GaussNB.predict(X_test)\n",
    "pred_m4 = time.time() - start_time\n",
    "\n",
    "# Calculer la précision\n",
    "acc_m4 = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"Gaussien_NB\"\n",
    "accuracy = acc_m4 * 100\n",
    "training_time = train_m4\n",
    "prediction_time = pred_m4\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b8c15",
   "metadata": {
    "id": "ec1b8c15"
   },
   "source": [
    "## Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7bcfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85b7bcfe",
    "outputId": "09549741-ca78-4822-8767-b87a6a37fbe5"
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle dans un fichier avec joblib\n",
    "model_filename = \"Audio_Classifier_GaussianNB.joblib\"\n",
    "joblib.dump(model_GaussNB, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea4171",
   "metadata": {
    "id": "65ea4171"
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d797c43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "7d797c43",
    "outputId": "6554f9ee-ab6f-4186-e0dd-946593e2d388"
   },
   "outputs": [],
   "source": [
    "# Select the file\n",
    "file_name = \"data/Baby/1-187207-A.wav\"\n",
    "# Predict the Class\n",
    "ML_prediction(file_name, 'Audio_Classifier_GaussianNB.joblib',feature_types)\n",
    "# play the file\n",
    "ipd.Audio(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73269775",
   "metadata": {
    "id": "73269775"
   },
   "source": [
    "# **Model 5 - KNN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a53a62",
   "metadata": {
    "id": "b2a53a62"
   },
   "source": [
    "## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708d0c2",
   "metadata": {
    "id": "0708d0c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Créer le classificateur k-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Entraîner le modèle\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "train_m5 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dbc07",
   "metadata": {
    "id": "611dbc07"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daddd2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "8daddd2e",
    "outputId": "093b03b4-8fb1-4666-f078-dcaf424b7397"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert X_test to NumPy array if it's not\n",
    "X_test = np.array(X_test)\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Calculer la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Afficher la précision par classe\n",
    "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Extraire les précisions par classe\n",
    "precisions = [class_report[label]['precision'] for label in label_encoder.classes_]\n",
    "\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_encoder.classes_, y=precisions)\n",
    "plt.title('Précision par classe (k-NN)')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Précision')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2aeed",
   "metadata": {
    "id": "86c2aeed"
   },
   "outputs": [],
   "source": [
    "# Mesurer le temps de prédiction\n",
    "start_time = time.time()\n",
    "y_pred = knn_model.predict(X_test)\n",
    "pred_m5 = time.time() - start_time\n",
    "\n",
    "# Calculer la précision\n",
    "acc_m5 = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"KNN\"\n",
    "accuracy = acc_m5 * 100\n",
    "training_time = train_m5\n",
    "prediction_time = pred_m5\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0f571",
   "metadata": {
    "id": "88a0f571"
   },
   "source": [
    "## Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ab043",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a4ab043",
    "outputId": "6e56830d-a3fb-45df-dd1b-f21ea1c663f1"
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle dans un fichier avec joblib\n",
    "model_filename = \"Audio_Classifier_KNN.joblib\"\n",
    "joblib.dump(knn_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cd184",
   "metadata": {
    "id": "744cd184"
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48231012",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "48231012",
    "outputId": "461b7c7c-026f-43de-d671-f4a6e9026f32"
   },
   "outputs": [],
   "source": [
    "# Select the file\n",
    "file_name = \"data/Baby/1-187207-A.wav\"\n",
    "# Predict the Class\n",
    "ML_prediction(file_name, 'Audio_Classifier_KNN.joblib',feature_types)\n",
    "# play the file\n",
    "ipd.Audio(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6e0e4",
   "metadata": {
    "id": "c4b6e0e4"
   },
   "source": [
    "# **Model 6 - SVM**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb0579",
   "metadata": {
    "id": "1eeb0579"
   },
   "source": [
    "## Fitting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a583bd7",
   "metadata": {
    "id": "2a583bd7"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Créer le classificateur SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Entraîner le modèle\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "train_m6 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fe457",
   "metadata": {
    "id": "1d5fe457"
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b6b4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "6c7b6b4a",
    "outputId": "cb1675e5-c3ae-4d26-ef05-243b032dc802"
   },
   "outputs": [],
   "source": [
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculer la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Afficher la précision par classe\n",
    "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "\n",
    "# Extraire les précisions par classe\n",
    "precisions = [class_report[label]['precision'] for label in label_encoder.classes_]\n",
    "\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_encoder.classes_, y=precisions)\n",
    "plt.title('Précision par classe (SVM)')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Précision')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf39e6",
   "metadata": {
    "id": "5dbf39e6"
   },
   "outputs": [],
   "source": [
    "# Mesurer le temps de prédiction\n",
    "start_time = time.time()\n",
    "y_pred = knn_model.predict(X_test)\n",
    "pred_m6 = time.time() - start_time\n",
    "\n",
    "# Calculer la précision\n",
    "acc_m6 = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Créer une nouvelle entrée à ajouter au DataFrame log\n",
    "model_name = \"SVM\"\n",
    "accuracy = acc_m6 * 100\n",
    "training_time = train_m6\n",
    "prediction_time = pred_m6\n",
    "\n",
    "log_data = {\"Model\": [model_name], \"Accuracy\": [accuracy], \"Training Time\": [training_time], \"Prediction Time\": [prediction_time]}\n",
    "\n",
    "# Créer le DataFrame à partir de log_data\n",
    "log_cols = [\"Model\", \"Accuracy\", \"Training Time\", \"Prediction Time\"]\n",
    "log_entry = pd.DataFrame(log_data, columns=log_cols)\n",
    "\n",
    "# Ajouter l'entrée au DataFrame log\n",
    "log = pd.concat([log, log_entry], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf98150",
   "metadata": {
    "id": "faf98150"
   },
   "source": [
    "## Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fef76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "154fef76",
    "outputId": "63aa6ff3-d5c8-4c6c-8399-b8129f7f01b5"
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle dans un fichier avec joblib\n",
    "model_filename = \"Audio_Classifier_SVM.joblib\"\n",
    "joblib.dump(svm_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553822b9",
   "metadata": {
    "id": "553822b9"
   },
   "source": [
    "## Testing the Model on Sample audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d0f6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "9b8d0f6f",
    "outputId": "9dadc71e-f8a7-44fc-d700-88841169d0ed"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select the file\n",
    "file_name = \"data/Baby/1-187207-A.wav\"\n",
    "# Predict the Class\n",
    "ML_prediction(file_name, 'Audio_Classifier_SVM.joblib',feature_types)\n",
    "# play the file\n",
    "ipd.Audio(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03187c",
   "metadata": {
    "id": "cc03187c"
   },
   "source": [
    "# **Comparative Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f06bd",
   "metadata": {
    "id": "648f06bd"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (17, 2)\n",
    "plt.rcParams[\"figure.dpi\"] = 550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d7c20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "0b7d7c20",
    "outputId": "e223600c-baab-41c9-9a85-d0bf5e915c21"
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Accuracy\", y=\"Model\", data=log, color=\"b\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1478af9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "c1478af9",
    "outputId": "d1cab12d-1f48-48f5-8bc0-b44d07789e6d"
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Training Time\", y=\"Model\", data=log, color=\"r\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Training Time\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Training Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd72200",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "7fd72200",
    "outputId": "2d9cf6c0-968c-4614-8fc6-182fb3183d4f"
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Prediction Time\", y=\"Model\", data=log, color=\"g\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xlabel(\"Prediction Time\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.title(\"Model Prediction Time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba7d13",
   "metadata": {
    "id": "61ba7d13"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1416529",
   "metadata": {
    "id": "e1416529"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbcbfa",
   "metadata": {
    "id": "cbfbcbfa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1112.254412,
   "end_time": "2021-05-18T14:04:08.302216",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-18T13:45:36.047804",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
